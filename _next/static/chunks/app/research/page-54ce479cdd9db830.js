(self.webpackChunk_N_E=self.webpackChunk_N_E||[]).push([[322],{4424:(e,s,i)=>{Promise.resolve().then(i.bind(i,5260))},5260:(e,s,i)=>{"use strict";i.r(s),i.d(s,{default:()=>n});var t=i(5155),a=i(2115);function n(){let[e,s]=(0,a.useState)("overview");return(0,t.jsxs)("div",{className:"min-h-screen bg-background",children:[(0,t.jsx)("section",{className:"section bg-white",children:(0,t.jsx)("div",{className:"container-narrow",children:(0,t.jsxs)("div",{className:"text-center mb-16",children:[(0,t.jsx)("h1",{className:"text-4xl lg:text-5xl font-serif font-bold text-primary mb-6",children:"Research"}),(0,t.jsx)("p",{className:"text-xl text-secondary leading-relaxed max-w-3xl mx-auto",children:"Advancing the frontiers of artificial intelligence through interdisciplinary research that bridges theory and practical applications."})]})})}),(0,t.jsx)("div",{className:"bg-gray-50 border-b border-gray-200 sticky top-16 z-40",children:(0,t.jsx)("div",{className:"container",children:(0,t.jsx)("div",{className:"flex space-x-8 overflow-x-auto",children:[{id:"overview",label:"Research Overview"},{id:"areas",label:"Research Areas"},{id:"methodology",label:"Methodologies"},{id:"collaborations",label:"Collaborations"}].map(i=>(0,t.jsx)("button",{onClick:()=>s(i.id),className:"py-4 px-2 border-b-2 font-medium text-sm whitespace-nowrap transition-colors ".concat(e===i.id?"border-accent text-accent":"border-transparent text-secondary hover:text-primary"),children:i.label},i.id))})})}),(0,t.jsx)("div",{className:"section",children:(0,t.jsxs)("div",{className:"container",children:["overview"===e&&(0,t.jsxs)("div",{className:"space-y-16",children:[(0,t.jsxs)("div",{className:"container-narrow",children:[(0,t.jsx)("h2",{className:"text-3xl font-serif font-semibold mb-8",children:"Research Vision"}),(0,t.jsxs)("div",{className:"prose prose-lg max-w-none",children:[(0,t.jsx)("p",{className:"text-lg leading-relaxed mb-6",children:"My research is driven by the vision of making artificial intelligence more efficient, accessible, and applicable to real-world problems. I focus on the intersection of theoretical advances and practical implementation, with particular emphasis on systems that can operate effectively in resource-constrained environments."}),(0,t.jsx)("p",{className:"text-lg leading-relaxed mb-6",children:"The core of my work lies in understanding the fundamental trade-offs between model complexity, computational efficiency, and performance. This understanding enables the development of AI systems that are not only powerful but also deployable in real-world scenarios."})]})]}),(0,t.jsxs)("div",{className:"bg-gray-50 rounded-lg p-8",children:[(0,t.jsx)("h2",{className:"text-3xl font-serif font-semibold mb-8 text-center",children:"Research Impact"}),(0,t.jsxs)("div",{className:"grid grid-cols-1 md:grid-cols-3 gap-8",children:[(0,t.jsxs)("div",{className:"text-center",children:[(0,t.jsx)("div",{className:"text-4xl font-bold text-accent mb-2",children:"15+"}),(0,t.jsx)("div",{className:"text-sm font-medium text-secondary",children:"Publications & Patents"})]}),(0,t.jsxs)("div",{className:"text-center",children:[(0,t.jsx)("div",{className:"text-4xl font-bold text-accent mb-2",children:"5"}),(0,t.jsx)("div",{className:"text-sm font-medium text-secondary",children:"Active Research Areas"})]}),(0,t.jsxs)("div",{className:"text-center",children:[(0,t.jsx)("div",{className:"text-4xl font-bold text-accent mb-2",children:"3"}),(0,t.jsx)("div",{className:"text-sm font-medium text-secondary",children:"Industry Collaborations"})]})]})]}),(0,t.jsxs)("div",{className:"container-narrow",children:[(0,t.jsx)("h2",{className:"text-3xl font-serif font-semibold mb-8",children:"Current Research Focus"}),(0,t.jsxs)("div",{className:"grid grid-cols-1 md:grid-cols-2 gap-8",children:[(0,t.jsxs)("div",{className:"card",children:[(0,t.jsx)("h3",{className:"text-xl font-semibold mb-4",children:"Efficient AI Systems"}),(0,t.jsx)("p",{className:"text-secondary mb-4",children:"Developing neural network architectures and optimization techniques that enable deployment on edge devices without sacrificing performance."}),(0,t.jsx)("div",{className:"text-sm text-accent",children:"Active Projects: 3"})]}),(0,t.jsxs)("div",{className:"card",children:[(0,t.jsx)("h3",{className:"text-xl font-semibold mb-4",children:"Computer Vision Applications"}),(0,t.jsx)("p",{className:"text-secondary mb-4",children:"Advancing perception systems for autonomous applications, with focus on real-time processing and robust performance in challenging conditions."}),(0,t.jsx)("div",{className:"text-sm text-accent",children:"Active Projects: 2"})]})]})]})]}),"areas"===e&&(0,t.jsxs)("div",{className:"space-y-12",children:[(0,t.jsxs)("div",{className:"text-center mb-12",children:[(0,t.jsx)("h2",{className:"text-3xl font-serif font-semibold mb-4",children:"Research Areas"}),(0,t.jsx)("p",{className:"text-lg text-secondary max-w-3xl mx-auto",children:"My research spans multiple domains within artificial intelligence, with each area contributing to the overarching goal of practical AI deployment."})]}),[{id:"computer-vision",title:"Computer Vision & Perception",description:"Developing advanced algorithms for image and video understanding, with applications in autonomous systems and robotics.",keywords:["Object Detection","Scene Understanding","Image Segmentation","Video Analysis"],projects:["Real-time object detection for autonomous vehicles","Multi-modal perception systems using camera and LiDAR","Efficient vision transformers for edge deployment"],publications:3},{id:"model-optimization",title:"Neural Network Optimization",description:"Research on model compression, quantization, and efficient architectures for deployment on resource-constrained devices.",keywords:["Model Compression","Quantization","Pruning","Knowledge Distillation"],projects:["Hardware-aware neural architecture search","Dynamic quantization for real-time inference","Efficient transformer architectures for mobile devices"],publications:2},{id:"transfer-learning",title:"Transfer Learning & Domain Adaptation",description:"Investigating methods to transfer knowledge across domains and tasks, enabling rapid adaptation to new applications.",keywords:["Domain Adaptation","Few-shot Learning","Meta-learning","Cross-domain Transfer"],projects:["Cross-domain object detection for surveillance systems","Few-shot learning for medical image analysis","Meta-learning algorithms for rapid deployment"],publications:4},{id:"autonomous-systems",title:"Autonomous Systems & Robotics",description:"AI for autonomous decision-making, including perception, planning, and control for robotic systems.",keywords:["Autonomous Navigation","Path Planning","Robot Control","SLAM"],projects:["Active perception using light curtains (CMU collaboration)","Intelligent ground vehicle prototype development","Multi-agent coordination algorithms"],publications:5}].map(e=>(0,t.jsxs)("div",{className:"card",children:[(0,t.jsxs)("div",{className:"flex items-start justify-between mb-6",children:[(0,t.jsx)("h3",{className:"text-2xl font-serif font-semibold text-primary",children:e.title}),(0,t.jsxs)("div",{className:"bg-accent text-white px-3 py-1 rounded-full text-sm",children:[e.publications," Publications"]})]}),(0,t.jsx)("p",{className:"text-lg text-secondary mb-6 leading-relaxed",children:e.description}),(0,t.jsxs)("div",{className:"grid grid-cols-1 lg:grid-cols-2 gap-8",children:[(0,t.jsxs)("div",{children:[(0,t.jsx)("h4",{className:"font-semibold mb-3",children:"Key Technologies"}),(0,t.jsx)("div",{className:"flex flex-wrap gap-2",children:e.keywords.map(e=>(0,t.jsx)("span",{className:"bg-gray-100 px-3 py-1 rounded-full text-sm text-secondary",children:e},e))})]}),(0,t.jsxs)("div",{children:[(0,t.jsx)("h4",{className:"font-semibold mb-3",children:"Current Projects"}),(0,t.jsx)("ul",{className:"space-y-2",children:e.projects.map((e,s)=>(0,t.jsxs)("li",{className:"text-sm text-secondary flex items-start",children:[(0,t.jsx)("span",{className:"text-accent mr-2",children:"â€¢"}),e]},s))})]})]})]},e.id))]}),"methodology"===e&&(0,t.jsxs)("div",{className:"space-y-12",children:[(0,t.jsxs)("div",{className:"text-center mb-12",children:[(0,t.jsx)("h2",{className:"text-3xl font-serif font-semibold mb-4",children:"Research Methodologies"}),(0,t.jsx)("p",{className:"text-lg text-secondary max-w-3xl mx-auto",children:"A comprehensive toolkit of techniques and approaches that enable rigorous investigation and robust experimental validation."})]}),(0,t.jsx)("div",{className:"grid grid-cols-1 md:grid-cols-2 gap-8",children:[{category:"Deep Learning",techniques:["Convolutional Neural Networks (CNNs)","Vision Transformers (ViTs)","Recurrent Neural Networks (RNNs)","Generative Adversarial Networks (GANs)","Attention Mechanisms","Self-supervised Learning"]},{category:"Optimization",techniques:["Gradient-based Optimization","Neural Architecture Search (NAS)","Hyperparameter Optimization","Multi-objective Optimization","Evolutionary Algorithms","Bayesian Optimization"]},{category:"Systems",techniques:["Real-time Processing Pipelines","Edge Computing Frameworks","Distributed Training Systems","Hardware Acceleration (GPU/TPU)","Model Serving Architectures","MLOps and CI/CD Pipelines"]},{category:"Experimental",techniques:["A/B Testing for ML Models","Statistical Significance Testing","Cross-validation Strategies","Benchmark Dataset Development","Performance Profiling","Ablation Studies"]}].map((e,s)=>(0,t.jsxs)("div",{className:"card",children:[(0,t.jsx)("h3",{className:"text-xl font-semibold mb-6 text-primary",children:e.category}),(0,t.jsx)("div",{className:"space-y-3",children:e.techniques.map((e,s)=>(0,t.jsxs)("div",{className:"flex items-center text-secondary hover:text-primary transition-colors",children:[(0,t.jsx)("div",{className:"w-2 h-2 bg-accent rounded-full mr-3 flex-shrink-0"}),(0,t.jsx)("span",{className:"text-sm",children:e})]},s))})]},s))}),(0,t.jsxs)("div",{className:"bg-gray-50 rounded-lg p-8",children:[(0,t.jsx)("h3",{className:"text-2xl font-serif font-semibold mb-6 text-center",children:"Research Process"}),(0,t.jsx)("div",{className:"grid grid-cols-1 md:grid-cols-4 gap-6",children:[{step:"1",title:"Problem Definition",desc:"Identify real-world challenges"},{step:"2",title:"Literature Review",desc:"Analyze existing solutions"},{step:"3",title:"Experimentation",desc:"Develop and test hypotheses"},{step:"4",title:"Validation",desc:"Evaluate on real applications"}].map((e,s)=>(0,t.jsxs)("div",{className:"text-center",children:[(0,t.jsx)("div",{className:"w-12 h-12 bg-accent text-white rounded-full flex items-center justify-center font-bold mb-4 mx-auto",children:e.step}),(0,t.jsx)("h4",{className:"font-semibold mb-2",children:e.title}),(0,t.jsx)("p",{className:"text-sm text-secondary",children:e.desc})]},s))})]})]}),"collaborations"===e&&(0,t.jsxs)("div",{className:"space-y-12",children:[(0,t.jsxs)("div",{className:"text-center mb-12",children:[(0,t.jsx)("h2",{className:"text-3xl font-serif font-semibold mb-4",children:"Research Collaborations"}),(0,t.jsx)("p",{className:"text-lg text-secondary max-w-3xl mx-auto",children:"Collaborative research partnerships that leverage diverse expertise and resources to tackle complex challenges in AI and machine learning."})]}),(0,t.jsx)("div",{className:"space-y-8",children:[{institution:"Carnegie Mellon University",lab:"RPAD Labs",project:"Active Perception using Light Curtains",duration:"2023",description:"Collaborative research on advanced perception systems for autonomous driving, focusing on novel sensing modalities and real-time processing algorithms."},{institution:"NeuroPixel.AI",lab:"Research Team",project:"Production ML Systems",duration:"2024 - Present",description:"Leading research initiatives on deploying deep learning models in production environments, with focus on efficiency and reliability."},{institution:"Industry Partners",lab:"Joint R&D",project:"Edge AI Solutions",duration:"2023 - Present",description:"Collaborative development of AI solutions for edge computing applications, including optimization for specific hardware platforms."}].map((e,s)=>(0,t.jsx)("div",{className:"card",children:(0,t.jsxs)("div",{className:"flex flex-col lg:flex-row lg:items-start gap-6",children:[(0,t.jsxs)("div",{className:"lg:w-64 flex-shrink-0",children:[(0,t.jsx)("h3",{className:"text-xl font-semibold text-primary mb-2",children:e.institution}),(0,t.jsx)("p",{className:"text-secondary font-medium mb-2",children:e.lab}),(0,t.jsx)("div",{className:"bg-gray-100 px-3 py-1 rounded-full text-sm text-secondary inline-block",children:e.duration})]}),(0,t.jsxs)("div",{className:"flex-1",children:[(0,t.jsx)("h4",{className:"text-lg font-semibold mb-3",children:e.project}),(0,t.jsx)("p",{className:"text-secondary leading-relaxed",children:e.description})]})]})},s))}),(0,t.jsxs)("div",{className:"bg-primary text-white rounded-lg p-8 text-center",children:[(0,t.jsx)("h3",{className:"text-2xl font-serif font-semibold mb-4",children:"Interested in Collaboration?"}),(0,t.jsx)("p",{className:"mb-6 opacity-90",children:"I'm always open to discussing new research opportunities and partnerships."}),(0,t.jsx)("a",{href:"/contact",className:"bg-white text-primary px-8 py-3 rounded-lg font-semibold hover:bg-gray-100 transition-colors",children:"Get in Touch"})]})]})]})})]})}}},e=>{var s=s=>e(e.s=s);e.O(0,[441,684,358],()=>s(4424)),_N_E=e.O()}]);